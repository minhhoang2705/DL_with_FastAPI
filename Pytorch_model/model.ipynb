{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "from PIL import Image\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/minhtran/Resources/Learning/AI_DL_Projects/DL_with_FastAPI/Pytorch_model/.env/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for cats_vs_dogs contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/cats_vs_dogs\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image', 'labels'],\n",
       "        num_rows: 23410\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET_NAME = 'cats_vs_dogs'\n",
    "datasets = load_dataset ( DATASET_NAME )\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.2\n",
    "datasets = datasets[\"train\"].train_test_split(test_size=TEST_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 64\n",
    "img_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatDogDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        images = self.data[idx][\"image\"]\n",
    "        labels = self.data[idx][\"labels\"]\n",
    "        \n",
    "        if self.transform:\n",
    "            images = self.transform(images)\n",
    "            \n",
    "        labels = torch.tensor(labels, dtype=torch.long)\n",
    "        \n",
    "        return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 512\n",
    "VAL_BATCH_SIZE = 256\n",
    "\n",
    "train_dataset = CatDogDataset(datasets[\"train\"], img_transform)\n",
    "test_dataset = CatDogDataset(datasets[\"test\"], img_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=VAL_BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatDogModel(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(CatDogModel, self).__init__()\n",
    "        \n",
    "        resnet_model = torchvision.models.resnet18(pretrained=True)\n",
    "        self.backbone = nn.Sequential(*list(resnet_model.children())[:-1])\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        in_features = resnet_model.fc.in_features\n",
    "        self.fc = nn.Linear(in_features, n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0083, 0.5857]], device='cuda:0') torch.Size([1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/minhtran/Resources/Learning/AI_DL_Projects/DL_with_FastAPI/Pytorch_model/.env/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/media/minhtran/Resources/Learning/AI_DL_Projects/DL_with_FastAPI/Pytorch_model/.env/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "N_Classes = 2\n",
    "model = CatDogModel(N_Classes).to(device)\n",
    "test_input = torch.randn(1, 3, 224, 224).to(device)\n",
    "with torch.no_grad():\n",
    "    test_output = model(test_input)\n",
    "    print(test_output, test_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train Loss: 0.6511853095647451, Val Loss: 0.6124513525711862\n",
      "Epoch: 2, Train Loss: 0.5461576226595286, Val Loss: 0.5547299447812533\n",
      "Epoch: 3, Train Loss: 0.533674554244892, Val Loss: 0.5335484978399778\n",
      "Epoch: 4, Train Loss: 0.515381004359271, Val Loss: 0.5251000664736095\n",
      "Epoch: 5, Train Loss: 0.509812476667198, Val Loss: 0.5254620846949125\n",
      "Epoch: 6, Train Loss: 0.5083155068191322, Val Loss: 0.5203162619942113\n",
      "Epoch: 7, Train Loss: 0.50482288808436, Val Loss: 0.5225035783491636\n",
      "Epoch: 8, Train Loss: 0.5046641456114279, Val Loss: 0.5164312783040499\n",
      "Epoch: 9, Train Loss: 0.5092968723258456, Val Loss: 0.519756942987442\n",
      "Epoch: 10, Train Loss: 0.5032809843888154, Val Loss: 0.5167634095016279\n",
      "Epoch: 11, Train Loss: 0.4982039203514924, Val Loss: 0.5156522769677011\n",
      "Epoch: 12, Train Loss: 0.4998998827225453, Val Loss: 0.5166904236141004\n",
      "Epoch: 13, Train Loss: 0.49590026285197286, Val Loss: 0.5155981779098511\n",
      "Epoch: 14, Train Loss: 0.49597351776586995, Val Loss: 0.512920302780051\n",
      "Epoch: 15, Train Loss: 0.4950416998283283, Val Loss: 0.5194609384787711\n",
      "Epoch: 16, Train Loss: 0.49757685049160105, Val Loss: 0.5138836126578482\n",
      "Epoch: 17, Train Loss: 0.49822214245796204, Val Loss: 0.514379156263251\n",
      "Epoch: 18, Train Loss: 0.49639796485772003, Val Loss: 0.5202377626770421\n",
      "Epoch: 19, Train Loss: 0.49614550696836934, Val Loss: 0.513381059232511\n",
      "Epoch: 20, Train Loss: 0.4922905548198803, Val Loss: 0.5151801705360413\n",
      "Epoch: 21, Train Loss: 0.4919957719944619, Val Loss: 0.5164333127046886\n",
      "Epoch: 22, Train Loss: 0.4931018054485321, Val Loss: 0.5149503083605516\n",
      "Epoch: 23, Train Loss: 0.49655844553096873, Val Loss: 0.5117797239830619\n",
      "Epoch: 24, Train Loss: 0.49503802769892924, Val Loss: 0.5141423125016061\n",
      "Epoch: 25, Train Loss: 0.4990388316077155, Val Loss: 0.5168720311240146\n",
      "Epoch: 26, Train Loss: 0.49286541503828923, Val Loss: 0.5148082391211861\n",
      "Epoch: 27, Train Loss: 0.4930326833918288, Val Loss: 0.5147506782883092\n",
      "Epoch: 28, Train Loss: 0.49399573657963725, Val Loss: 0.5272791118998277\n",
      "Epoch: 29, Train Loss: 0.4974016225015795, Val Loss: 0.516502088622043\n",
      "Epoch: 30, Train Loss: 0.49475760073275177, Val Loss: 0.5147070476883336\n",
      "Epoch: 31, Train Loss: 0.49224982471079437, Val Loss: 0.5162980870196694\n",
      "Epoch: 32, Train Loss: 0.49217960157909907, Val Loss: 0.5147660202101657\n",
      "Epoch: 33, Train Loss: 0.4928111876990344, Val Loss: 0.5138040247716402\n",
      "Epoch: 34, Train Loss: 0.4934294062691766, Val Loss: 0.516231496083109\n",
      "Epoch: 35, Train Loss: 0.4956915612156327, Val Loss: 0.5173163947306181\n",
      "Epoch: 36, Train Loss: 0.4947087450607403, Val Loss: 0.5147387432424646\n",
      "Epoch: 37, Train Loss: 0.49475169504011, Val Loss: 0.5137088110572413\n",
      "Epoch: 38, Train Loss: 0.49524741478868434, Val Loss: 0.5165131029329801\n",
      "Epoch: 39, Train Loss: 0.49572259509885636, Val Loss: 0.531015871386779\n",
      "Epoch: 40, Train Loss: 0.493012440365714, Val Loss: 0.5179016590118408\n",
      "Epoch: 41, Train Loss: 0.4931176135668883, Val Loss: 0.5199721690855528\n",
      "Epoch: 42, Train Loss: 0.49590436026856705, Val Loss: 0.5439804400268354\n",
      "Epoch: 43, Train Loss: 0.4997195480643092, Val Loss: 0.5292011468034041\n",
      "Epoch: 44, Train Loss: 0.49930174527941523, Val Loss: 0.5169756255651775\n",
      "Epoch: 45, Train Loss: 0.4927366955860241, Val Loss: 0.5154151900818473\n",
      "Epoch: 46, Train Loss: 0.49406745546572917, Val Loss: 0.5139163842326716\n",
      "Epoch: 47, Train Loss: 0.49331407289247253, Val Loss: 0.5228874934347052\n",
      "Epoch: 48, Train Loss: 0.49895256677189387, Val Loss: 0.5236415988520572\n",
      "Epoch: 49, Train Loss: 0.4927566317287651, Val Loss: 0.5199942541749853\n",
      "Epoch: 50, Train Loss: 0.49277541766295563, Val Loss: 0.5187093160654369\n",
      "Epoch: 51, Train Loss: 0.4936451114512779, Val Loss: 0.5249639027997067\n",
      "Epoch: 52, Train Loss: 0.492914080619812, Val Loss: 0.5157080214274558\n",
      "Epoch: 53, Train Loss: 0.4932308140638712, Val Loss: 0.5158938294962833\n",
      "Epoch: 54, Train Loss: 0.4956811424848196, Val Loss: 0.529543178646188\n",
      "Epoch: 55, Train Loss: 0.49594824136914434, Val Loss: 0.5157474546056044\n",
      "Epoch: 56, Train Loss: 0.4956953863839845, Val Loss: 0.5150306554217088\n",
      "Epoch: 57, Train Loss: 0.4984044746772663, Val Loss: 0.5139217580619612\n",
      "Epoch: 58, Train Loss: 0.49332207119142685, Val Loss: 0.5144766631879305\n",
      "Epoch: 59, Train Loss: 0.4926403704527262, Val Loss: 0.5151753206002084\n",
      "Epoch: 60, Train Loss: 0.4924214772275976, Val Loss: 0.5260362891774428\n",
      "Epoch: 61, Train Loss: 0.49534699562433604, Val Loss: 0.5141359081393794\n",
      "Epoch: 62, Train Loss: 0.4928909854308979, Val Loss: 0.5141077888639349\n",
      "Epoch: 63, Train Loss: 0.4941002356039511, Val Loss: 0.5159196085051486\n",
      "Epoch: 64, Train Loss: 0.49399892542813273, Val Loss: 0.5201865058196219\n",
      "Epoch: 65, Train Loss: 0.49478506397556615, Val Loss: 0.5153401572453348\n",
      "Epoch: 66, Train Loss: 0.4928417954895947, Val Loss: 0.5197370303304572\n",
      "Epoch: 67, Train Loss: 0.4954460778751889, Val Loss: 0.5322874455075515\n",
      "Epoch: 68, Train Loss: 0.49803648929338196, Val Loss: 0.5157788458623385\n",
      "Epoch: 69, Train Loss: 0.4933230643336837, Val Loss: 0.5164502765003004\n",
      "Epoch: 70, Train Loss: 0.49236739245620936, Val Loss: 0.515669551334883\n",
      "Epoch: 71, Train Loss: 0.4938210522806322, Val Loss: 0.515238156444148\n",
      "Epoch: 72, Train Loss: 0.49251117094143015, Val Loss: 0.5248491811124902\n",
      "Epoch: 73, Train Loss: 0.4965105950832367, Val Loss: 0.5155484990069741\n",
      "Epoch: 74, Train Loss: 0.4940323225549749, Val Loss: 0.5164256911528738\n",
      "Epoch: 75, Train Loss: 0.49452646278046275, Val Loss: 0.5171183849635878\n",
      "Epoch: 76, Train Loss: 0.4934696305442501, Val Loss: 0.5156737362083635\n",
      "Epoch: 77, Train Loss: 0.4919946056765479, Val Loss: 0.5148791184550837\n",
      "Epoch: 78, Train Loss: 0.4941907299531473, Val Loss: 0.5160037404612491\n",
      "Epoch: 79, Train Loss: 0.49786625037322174, Val Loss: 0.5199458457921681\n",
      "Epoch: 80, Train Loss: 0.49605039487013947, Val Loss: 0.5223300206033807\n",
      "Epoch: 81, Train Loss: 0.49635714614713516, Val Loss: 0.5145249319703955\n",
      "Epoch: 82, Train Loss: 0.49742991940395254, Val Loss: 0.5561589049665552\n",
      "Epoch: 83, Train Loss: 0.4951789564377553, Val Loss: 0.5181246572419217\n",
      "Epoch: 84, Train Loss: 0.49111505215232437, Val Loss: 0.514259154859342\n",
      "Epoch: 85, Train Loss: 0.49074505954175385, Val Loss: 0.5143716664690721\n",
      "Epoch: 86, Train Loss: 0.49258865778510635, Val Loss: 0.5214313927449679\n",
      "Epoch: 87, Train Loss: 0.49439779971096964, Val Loss: 0.5176914177442852\n",
      "Epoch: 88, Train Loss: 0.49660857867550207, Val Loss: 0.5147963244664041\n",
      "Epoch: 89, Train Loss: 0.49380589981336853, Val Loss: 0.5158243163635856\n",
      "Epoch: 90, Train Loss: 0.49100497606638316, Val Loss: 0.5154261259656203\n",
      "Epoch: 91, Train Loss: 0.4908982289803995, Val Loss: 0.5178553650253698\n",
      "Epoch: 92, Train Loss: 0.4948754608631134, Val Loss: 0.516568627796675\n",
      "Epoch: 93, Train Loss: 0.49385222470438156, Val Loss: 0.5202477919427972\n",
      "Epoch: 94, Train Loss: 0.49153152349832896, Val Loss: 0.5155736709895887\n",
      "Epoch: 95, Train Loss: 0.49485332659772924, Val Loss: 0.5153340775715677\n",
      "Epoch: 96, Train Loss: 0.4992138227900943, Val Loss: 0.5270276508833233\n",
      "Epoch: 97, Train Loss: 0.4947656868277369, Val Loss: 0.5146377604258688\n",
      "Epoch: 98, Train Loss: 0.4932823092550845, Val Loss: 0.5152672544906014\n",
      "Epoch: 99, Train Loss: 0.4963169460361068, Val Loss: 0.5214851906425074\n",
      "Epoch: 100, Train Loss: 0.4929724545092196, Val Loss: 0.5143188206773055\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "LR = 1e-3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_losses = []\n",
    "    model.train()\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "        \n",
    "    train_loss = sum(train_losses) / len(train_losses)\n",
    "    \n",
    "    val_losses = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            val_losses.append(loss.item())\n",
    "            \n",
    "    val_loss = sum(val_losses) / len(val_losses)\n",
    "    \n",
    "    print(f'Epoch: {epoch + 1}, Train Loss: {train_loss}, Val Loss: {val_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = 'catdog_model.pt'\n",
    "torch.save(model.state_dict(), SAVE_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
